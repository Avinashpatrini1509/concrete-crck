{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bae28526",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "13e8c5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "01aa486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "77ffcbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a987a7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pertinent libraries\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import glob as glob\n",
    "import numpy as np\n",
    "# [Keras Models]\n",
    "# import the Keras implementations of VGG16, VGG19, InceptionV3 and Xception models\n",
    "# the model used here is VGG16\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import tensorflow\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8df44818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e3e163c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ef5d39bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1354e8e3",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d226bbd",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "96ba8d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 600 image(s) found.\n",
      "Output directory set to E:\\Bali\\Kaggle Competition\\train\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=224x224 at 0x16E7F2ACD90>: 100%|█| 600/600 [00:01<00:00, 443.96 Samples\n",
      "Processing <PIL.Image.Image image mode=RGB size=224x224 at 0x16EB4A4AF10>: 100%|█| 3000/3000 [00:06<00:00, 434.73 Sampl\n"
     ]
    }
   ],
   "source": [
    "import Augmentor\n",
    "p = Augmentor.Pipeline(\"E:\\\\Bali\\\\Kaggle Competition\\\\train\")\n",
    "p.rotate90(probability=0.7)\n",
    "#p.zoom(probability=0.5, min_factor=1.1, max_factor=1.3)\n",
    "p.flip_random(probability = 0.2)\n",
    "#p.skew(0.5,magnitude=1)\n",
    "p.random_brightness(0.3,0.75,1.25)\n",
    "p.process()\n",
    "p.sample(3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c37fe73",
   "metadata": {},
   "source": [
    "## Bilateral Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1ef0a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bilateral_filtering(directory):\n",
    "    for filename in os.listdir(directory):       \n",
    "        # load the image\n",
    "        img = cv2.imread(os.path.join(directory, filename))\n",
    "\n",
    "        # apply bilateral filtering\n",
    "        filtered_img = cv2.bilateralFilter(img, 6, 75,1475)\n",
    "\n",
    "        # save the filtered image\n",
    "        cv2.imwrite(os.path.join(directory,filename), filtered_img)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb670e0",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "27059659",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"E:\\\\Bali\\\\Kaggle Competition\\\\train\\\\output\\\\Positive\"\n",
    "Bilateral_filtering(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b1e86417",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"E:\\\\Bali\\\\Kaggle Competition\\\\train\\\\output\\\\Negative\"\n",
    "Bilateral_filtering(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d784fcf",
   "metadata": {},
   "source": [
    "### Val and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ad276c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"E:\\\\Bali\\\\Kaggle Competition\\\\valid\\\\Positive\"\n",
    "Bilateral_filtering(directory)\n",
    "directory = \"E:\\\\Bali\\\\Kaggle Competition\\\\valid\\\\Negative\"\n",
    "Bilateral_filtering(directory)\n",
    "\n",
    "directory = \"E:\\\\Bali\\\\Kaggle Competition\\\\test\\\\Positive\"\n",
    "Bilateral_filtering(directory)\n",
    "directory = \"E:\\\\Bali\\\\Kaggle Competition\\\\test\\\\Negative\"\n",
    "Bilateral_filtering(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d6fd2b",
   "metadata": {},
   "source": [
    "## Grayscaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c91d426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grayscaling(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            image = cv2.imread(filepath)\n",
    "            gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            cv2.imwrite(filepath, gray_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d880d957",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "896f0cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"E:\\\\Bali\\\\Kaggle Competition\\\\train\\\\output\\\\Positive\"\n",
    "Grayscaling(directory)\n",
    "directory = \"E:\\\\Bali\\\\Kaggle Competition\\\\train\\\\output\\\\Negative\"\n",
    "Grayscaling(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581974fc",
   "metadata": {},
   "source": [
    "### Val and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "990ff3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"E:\\\\Bali\\\\Kaggle Competition\\\\valid\\\\Positive\"\n",
    "Grayscaling(directory)\n",
    "directory = \"E:\\\\Bali\\\\Kaggle Competition\\\\valid\\\\Negative\"\n",
    "Grayscaling(directory)\n",
    "\n",
    "directory = \"E:\\\\Bali\\\\Kaggle Competition\\\\test\\\\Positive\"\n",
    "Grayscaling(directory)\n",
    "directory = \"E:\\\\Bali\\\\Kaggle Competition\\\\test\\\\Negative\"\n",
    "Grayscaling(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543fae25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4cf64a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0734a4e2",
   "metadata": {},
   "source": [
    "# Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "1255a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_images = os.listdir(\"E:\\\\Bali\\\\Kaggle Competition\\\\train\\\\output\\\\Negative\")\n",
    "positive_images = os.listdir(\"E:\\\\Bali\\\\Kaggle Competition\\\\train\\\\output\\\\Positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c11150ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "image_resize = 224\n",
    "batch_size_training = 50\n",
    "batch_size_validation = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "da985042",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bf328002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3600 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator.flow_from_directory(\n",
    "    \"E:\\\\Bali\\\\Kaggle Competition\\\\train\\\\output\",\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_training,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0eb969b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'E:\\\\Bali\\\\Kaggle Competition\\\\valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_validation,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74c18e9",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2bc21e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(ResNet50(\n",
    "    include_top=False,\n",
    "    pooling='avg',\n",
    "    weights='imagenet',\n",
    "    ))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "cfab77b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(2, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5af8c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b9bd6cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 2048)              23587712  \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 2)                 4098      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 2)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,591,816\n",
      "Trainable params: 4,104\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "52f30729",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[tfa.metrics.F1Score(num_classes=2, average=\"micro\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e8fcb5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch_training = len(train_generator)\n",
    "steps_per_epoch_validation = len(validation_generator)\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "51abe3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19804\\251737888.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  fit_history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 32s 405ms/step - loss: 0.4496 - f1_score: 0.8736 - val_loss: 0.3798 - val_f1_score: 0.9800\n",
      "Epoch 2/20\n",
      "72/72 [==============================] - 29s 396ms/step - loss: 0.3414 - f1_score: 0.9875 - val_loss: 0.3190 - val_f1_score: 0.9900\n",
      "Epoch 3/20\n",
      "72/72 [==============================] - 28s 393ms/step - loss: 0.2899 - f1_score: 0.9911 - val_loss: 0.2732 - val_f1_score: 0.9900\n",
      "Epoch 4/20\n",
      "72/72 [==============================] - 28s 390ms/step - loss: 0.2506 - f1_score: 0.9933 - val_loss: 0.2412 - val_f1_score: 0.9900\n",
      "Epoch 5/20\n",
      "72/72 [==============================] - 30s 412ms/step - loss: 0.2194 - f1_score: 0.9953 - val_loss: 0.2112 - val_f1_score: 0.9850\n",
      "Epoch 6/20\n",
      "72/72 [==============================] - 30s 408ms/step - loss: 0.1934 - f1_score: 0.9967 - val_loss: 0.1843 - val_f1_score: 0.9950\n",
      "Epoch 7/20\n",
      "72/72 [==============================] - 30s 410ms/step - loss: 0.1717 - f1_score: 0.9978 - val_loss: 0.1634 - val_f1_score: 0.9950\n",
      "Epoch 8/20\n",
      "72/72 [==============================] - 31s 428ms/step - loss: 0.1536 - f1_score: 0.9981 - val_loss: 0.1469 - val_f1_score: 1.0000\n",
      "Epoch 9/20\n",
      "72/72 [==============================] - 30s 410ms/step - loss: 0.1386 - f1_score: 0.9986 - val_loss: 0.1324 - val_f1_score: 1.0000\n",
      "Epoch 10/20\n",
      "72/72 [==============================] - 30s 408ms/step - loss: 0.1258 - f1_score: 0.9986 - val_loss: 0.1208 - val_f1_score: 1.0000\n",
      "Epoch 11/20\n",
      "72/72 [==============================] - 30s 410ms/step - loss: 0.1150 - f1_score: 0.9986 - val_loss: 0.1097 - val_f1_score: 1.0000\n",
      "Epoch 12/20\n",
      "72/72 [==============================] - 30s 410ms/step - loss: 0.1056 - f1_score: 0.9986 - val_loss: 0.0998 - val_f1_score: 1.0000\n",
      "Epoch 13/20\n",
      "72/72 [==============================] - 30s 410ms/step - loss: 0.0943 - f1_score: 0.9997 - val_loss: 0.0922 - val_f1_score: 1.0000\n",
      "Epoch 14/20\n",
      "72/72 [==============================] - 29s 396ms/step - loss: 0.0863 - f1_score: 1.0000 - val_loss: 0.0855 - val_f1_score: 1.0000\n",
      "Epoch 15/20\n",
      "72/72 [==============================] - 28s 391ms/step - loss: 0.0797 - f1_score: 1.0000 - val_loss: 0.0797 - val_f1_score: 1.0000\n",
      "Epoch 16/20\n",
      "72/72 [==============================] - 28s 391ms/step - loss: 0.0738 - f1_score: 1.0000 - val_loss: 0.0745 - val_f1_score: 1.0000\n",
      "Epoch 17/20\n",
      "72/72 [==============================] - 28s 391ms/step - loss: 0.0685 - f1_score: 1.0000 - val_loss: 0.0695 - val_f1_score: 1.0000\n",
      "Epoch 18/20\n",
      "72/72 [==============================] - 28s 392ms/step - loss: 0.0638 - f1_score: 1.0000 - val_loss: 0.0649 - val_f1_score: 1.0000\n",
      "Epoch 19/20\n",
      "72/72 [==============================] - 28s 392ms/step - loss: 0.0595 - f1_score: 1.0000 - val_loss: 0.0611 - val_f1_score: 1.0000\n",
      "Epoch 20/20\n",
      "72/72 [==============================] - 28s 392ms/step - loss: 0.0556 - f1_score: 1.0000 - val_loss: 0.0573 - val_f1_score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "fit_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_training,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=steps_per_epoch_validation,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c40363ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19804\\1865615202.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  model.evaluate_generator(test_generator,steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05357326939702034, 1.0]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(test_generator,steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6eecb912",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('resnet_model1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0829e36",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d87aca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d45d5d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg = Sequential()\n",
    "model_vgg.add(VGG16(\n",
    "    include_top=False,\n",
    "    pooling='avg',\n",
    "    weights='imagenet',\n",
    "    ))\n",
    "model_vgg.add(Dense(num_classes, activation='softmax'))\n",
    "model_vgg.add(Dense(num_classes, activation ='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9460743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "59b5adda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 512)               14714688  \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 2)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,715,720\n",
      "Trainable params: 1,032\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a1dd5999",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[tfa.metrics.F1Score(num_classes=2, average=\"micro\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5a673d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19804\\2788884500.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  fit_history_vgg = model_vgg.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 52s 710ms/step - loss: 0.5394 - f1_score: 0.8117 - val_loss: 0.3931 - val_f1_score: 0.9650\n",
      "Epoch 2/20\n",
      "72/72 [==============================] - 51s 707ms/step - loss: 0.3707 - f1_score: 0.9439 - val_loss: 0.3265 - val_f1_score: 0.9700\n",
      "Epoch 3/20\n",
      "72/72 [==============================] - 51s 709ms/step - loss: 0.3169 - f1_score: 0.9611 - val_loss: 0.2895 - val_f1_score: 0.9650\n",
      "Epoch 4/20\n",
      "72/72 [==============================] - 51s 706ms/step - loss: 0.2783 - f1_score: 0.9717 - val_loss: 0.2592 - val_f1_score: 0.9650\n",
      "Epoch 5/20\n",
      "72/72 [==============================] - 51s 707ms/step - loss: 0.2490 - f1_score: 0.9747 - val_loss: 0.2342 - val_f1_score: 0.9750\n",
      "Epoch 6/20\n",
      "72/72 [==============================] - 51s 707ms/step - loss: 0.2238 - f1_score: 0.9803 - val_loss: 0.2102 - val_f1_score: 0.9800\n",
      "Epoch 7/20\n",
      "72/72 [==============================] - 51s 707ms/step - loss: 0.2022 - f1_score: 0.9817 - val_loss: 0.1910 - val_f1_score: 0.9850\n",
      "Epoch 8/20\n",
      "72/72 [==============================] - 51s 706ms/step - loss: 0.1807 - f1_score: 0.9861 - val_loss: 0.1760 - val_f1_score: 0.9800\n",
      "Epoch 9/20\n",
      "72/72 [==============================] - 50s 691ms/step - loss: 0.1618 - f1_score: 0.9892 - val_loss: 0.1570 - val_f1_score: 0.9800\n",
      "Epoch 10/20\n",
      "72/72 [==============================] - 51s 707ms/step - loss: 0.1464 - f1_score: 0.9917 - val_loss: 0.1496 - val_f1_score: 0.9750\n",
      "Epoch 11/20\n",
      "72/72 [==============================] - 51s 708ms/step - loss: 0.1320 - f1_score: 0.9931 - val_loss: 0.1345 - val_f1_score: 0.9850\n",
      "Epoch 12/20\n",
      "72/72 [==============================] - 51s 707ms/step - loss: 0.1204 - f1_score: 0.9944 - val_loss: 0.1235 - val_f1_score: 0.9900\n",
      "Epoch 13/20\n",
      "72/72 [==============================] - 51s 708ms/step - loss: 0.1098 - f1_score: 0.9964 - val_loss: 0.1182 - val_f1_score: 0.9850\n",
      "Epoch 14/20\n",
      "72/72 [==============================] - 51s 707ms/step - loss: 0.1015 - f1_score: 0.9969 - val_loss: 0.1085 - val_f1_score: 0.9850\n",
      "Epoch 15/20\n",
      "72/72 [==============================] - 51s 706ms/step - loss: 0.0940 - f1_score: 0.9969 - val_loss: 0.0994 - val_f1_score: 0.9850\n",
      "Epoch 16/20\n",
      "72/72 [==============================] - 51s 706ms/step - loss: 0.0876 - f1_score: 0.9972 - val_loss: 0.0946 - val_f1_score: 0.9850\n",
      "Epoch 17/20\n",
      "72/72 [==============================] - 51s 707ms/step - loss: 0.0820 - f1_score: 0.9972 - val_loss: 0.0885 - val_f1_score: 0.9900\n",
      "Epoch 18/20\n",
      "72/72 [==============================] - 51s 708ms/step - loss: 0.0767 - f1_score: 0.9972 - val_loss: 0.0831 - val_f1_score: 0.9900\n",
      "Epoch 19/20\n",
      "72/72 [==============================] - 51s 705ms/step - loss: 0.0721 - f1_score: 0.9972 - val_loss: 0.0772 - val_f1_score: 0.9900\n",
      "Epoch 20/20\n",
      "72/72 [==============================] - 51s 707ms/step - loss: 0.0680 - f1_score: 0.9972 - val_loss: 0.0731 - val_f1_score: 0.9950\n"
     ]
    }
   ],
   "source": [
    "fit_history_vgg = model_vgg.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_training,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=steps_per_epoch_validation,\n",
    "    verbose=1,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "bb30943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg.save('vgg16_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "072e518a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data_generator_test = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "test_generator = data_generator_test.flow_from_directory(\n",
    "    'E:\\\\Bali\\\\Kaggle Competition\\\\test',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8d237779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19804\\1474210604.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  model_vgg.evaluate_generator(test_generator,steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06273682415485382, 1.0]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vgg.evaluate_generator(test_generator,steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
